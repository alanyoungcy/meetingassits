from fastapi import FastAPI, UploadFile, File
from openai import OpenAI, WhisperModel
import openai
from pydantic import BaseModel
import os

app = FastAPI()

# Initialize Whisper
model = WhisperModel(language="Cantonese")  # Assuming Whisper supports Cantonese

# Initialize OpenAI API
openai.api_key = os.getenv("OPENAI_API_KEY")

class MeetingSummaryRequest(BaseModel):
    text: str
    documents: list[str]

@app.post("/transcribe/")
async def transcribe_audio(file: UploadFile = File(...)):
    # Process the file for transcription
    audio_data = await file.read()
    transcription = model.transcribe(audio_data)
    return {"transcription": transcription}

@app.post("/generate_summary/")
async def generate_summary(request: MeetingSummaryRequest):
    # Use RAG for augmentation and summarization
    context = " ".join(request.documents)  # Merging documents for augmentation
    summary = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": context},
            {"role": "user", "content": request.text}
        ]
    )
    return {"summary": summary.choices[0].message.content}

@app.post("/formatted_summary/")
async def formatted_summary(summary: str):
    # Apply template for formatted meeting minutes
    formatted_summary = f"## Meeting Minutes\n\n### Summary\n{summary}\n\n---\nGenerated by AI Assistant."
    return {"formatted_summary": formatted_summary}